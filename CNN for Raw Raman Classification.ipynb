{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    " - Raman has been used to classify mineral types and has growing use in biomedical applications\n",
    " - Traditional methods rely on baseline normalization and PCA to extract features\n",
    " - Recent work has shown that CNN's can outperform manual baseline normalization techniques\n",
    " - This project is to train a CNN to process raw Raman spectra from the RUFF database and apply transfer learning to process raw raman from other applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "from lib.utils import RamanSample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/processed/spectra_with_labels.csv\"\n",
    "path = \"data/processed/sample.csv\"\n",
    "\n",
    "my_data = pd.read_csv(path).as_matrix()\n",
    "y, X = my_data[:, 0], my_data[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brucite' 'Dufrenoysite' 'Ferrierite-K' 'Linarite' 'Lorenzenite'\n",
      " 'Stellerite' 'Trona' 'Wakabayashilite' 'Zussmanite' 'Franckeite'] [[0.183102 0.060612001 0.053993002000000005 0.193037 0.29520799999999997\n",
      "  0.27611399999999997 0.123426 0.072893001 0.21088600000000002 0.2897]\n",
      " [1896.963 1894.661 1902.741 1899.266 1889.674 1878.457 1868.48\n",
      "  1859.2879999999998 1848.5479999999998 1826.7839999999999]\n",
      " [0.108215 0.8623049999999999 0.68576 0.337219 0.27920500000000004\n",
      "  0.50058 0.6892699999999999 0.588196 0.308655 0.15329]\n",
      " [14.39701 14.91875 15.628789999999999 17.03975 18.77167\n",
      "  20.287470000000003 21.048779999999997 23.19223 24.818379999999998\n",
      "  26.434279999999998]\n",
      " [159.3792 157.3322 155.2488 153.2598 151.6223 150.3969 149.3085 148.1007\n",
      "  146.7592 145.5281]\n",
      " [100.9706 98.60374 96.03226 93.30836 90.44233 87.32395 83.93369 80.62957\n",
      "  77.80696 72.89535]\n",
      " [47.27539 43.613279999999996 41.32812 41.94531 45.21094 48.17969\n",
      "  44.29492 43.60938 62.93164 97.57616999999999]\n",
      " [314.002 331.4 334.523 298.76599999999996 222.611 167.356 161.827\n",
      "  184.44799999999998 199.72400000000002 206.65900000000002]\n",
      " [24.49902 23.35452 22.28456 21.33791 20.5708 19.45111 18.85614 18.24586\n",
      "  17.62325 16.880979999999997]\n",
      " [96.05957 96.83251 97.84971999999999 98.83652 97.99426 94.42684 90.83627\n",
      "  89.72758 91.11581 92.84501]]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "num_labels = len(set(y_encoded))\n",
    "one_hot_encoder = OneHotEncoder(sparse=True)\n",
    "y_train = one_hot_encoder.fit_transform(y_encoded.reshape(-1,1))\n",
    "X_train = np.expand_dims(X, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2203"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv1D, MaxPooling1D, AveragePooling1D, Flatten, LeakyReLU, Dropout, GlobalAveragePooling1D\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_33 (Conv1D)           (None, 2000, 64)          320       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 1000, 32)          8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 500, 32)           4128      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_7 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 500)               16500     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2203)              1103703   \n",
      "=================================================================\n",
      "Total params: 1,132,875\n",
      "Trainable params: 1,132,875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=4, padding='same', activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(MaxPooling1D(pool_size=2, padding='valid'))\n",
    "#model.add(LeakyReLU(alpha=.2))\n",
    "model.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2, padding='valid'))\n",
    "#model.add(LeakyReLU(alpha=.2))\n",
    "model.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "#model.add(LeakyReLU(alpha=.2))\n",
    "model.add(MaxPooling1D(pool_size=2, padding='valid'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(num_labels, activation=\"softmax\"))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "checkpoint = ModelCheckpoint(\"models/raman.s\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 6s 7ms/step - loss: 10.9977 - acc: 0.0200 - val_loss: 9.7992 - val_acc: 0.0900\n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 6s 7ms/step - loss: 10.8257 - acc: 0.0222 - val_loss: 10.8037 - val_acc: 0.0300\n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 6s 7ms/step - loss: 10.0391 - acc: 0.0378 - val_loss: 9.2883 - val_acc: 0.1900\n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 6s 7ms/step - loss: 10.0675 - acc: 0.0222 - val_loss: 8.9618 - val_acc: 0.0700\n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 7s 8ms/step - loss: 9.3874 - acc: 0.0367 - val_loss: 10.1165 - val_acc: 0.0500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1167e3a58>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=5\n",
    "batch_size=500\n",
    "\n",
    "model.fit(X_train[:1000, :], y_train[:1000], epochs=epochs, batch_size=batch_size, \n",
    "          verbose=1, validation_split=0.1, shuffle=True,\n",
    "          callbacks=[checkpoint]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:raman]",
   "language": "python",
   "name": "conda-env-raman-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
